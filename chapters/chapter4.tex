\section{Chapter 4 - LP Solutions}
\subsection{Tuesday 02/11/2025}
\subsubsection{Simplex Algorithm}
For an algorithm that solves an LP, we can define its input as an LP in the form
\begin{align}
  \text{minimize} & \quad c^\top x \\
  \text{subject to} & \quad Ax = b \\
  & \quad x \succeq 0
\end{align}
where $c \in \mathbb{R}^n, b \in \mathbb{R}^m, A \in \mathbb{R}^{m \times n}$.
The optimal solution lies at one of the vertices of the problem which we can represent as $J_1^0, \dots, J_m^0$.
The steps of the algoirthm include
\begin{enumerate}
    \item $B = (A_{j1}, \dots, A_{jm})$
    \item Calculate the reduced cost in all basic directions as 
          $\bar{c}_j = c_j - c_B^\top B^{-1} A_j, \quad \forall j \notin J^k$
    \item If $\bar{c}_j \geq 0 \quad \forall j \notin J^k$ then this is the optimal solution.
          Otherwise, we have a collection of reduced costs for every non-basic variable we have.
          We then pick the calculate them one by one and pick the first one that is less than zero.
          We do this so we don't have to calculate each reduced cost to identify a descent direction.
    \item Calculate the basic variables $x_B = B^{-1} b$.
    \item Calculate the basic components of the basic direction $d_b = B^{-1} A_p$.
    \item Move along $x_B + \alpha d_B$ where $\alpha_i = -\frac{x_{B i}}{d_{b i}}$ if $d_{b i} < 0$
          We will choose the total step $\alpha$ as the $\alpha_i$ that results in the smallest value.
\end{enumerate}
For an example for part 3, consider a reduced cost vector:
\[
\bar{c} = \begin{bmatrix}
2 \\
-2 \\
-4 \\
\vdots \\
-10000
\end{bmatrix}
\]
In this case, we would pick the first value less than zero, which is $-2$.

\subsubsection{Simplex Example}
We can take an example problem
\begin{align}
  \text{minimize} & \quad -x_1 - 2x_2 \\
  \text{subject to} & \quad x_1 + x_2 \leq 1 \\
  & \quad x_1 - x_2 \leq 1 \\
  & \quad x_1, x_2 \geq 0
\end{align}

which can be turned into standard form 
\begin{align}
  \text{minimize} & \quad c^\top x \\
  \text{subject to} & \quad Ax = b \\
  & \quad  x \succeq 0
\end{align}
with parameters 
\begin{align}
    A = 
  \begin{bmatrix}
     1 & 1 & 1 & 0 \\
     1 & -1 & 0 & 1
  \end{bmatrix}
  \quad
  b = 
  \begin{bmatrix}
    1 \\ 1
  \end{bmatrix}
  \quad
  c = 
  \begin{bmatrix}
    1 \\ -2 \\ 0 \\ 0
  \end{bmatrix}
\end{align}

\begin{align}
    J^0 = \{ 3,4 \}
    \quad 
    B = 
    \begin{bmatrix}
        1 & 0 \\ 0 & 2
    \end{bmatrix}
    \quad
    x_B = 
    \begin{bmatrix}
        x_3 \\ x_4
    \end{bmatrix} 
    = B^{-1} b = 
    \begin{bmatrix}
        1 \\ 1
    \end{bmatrix}
\end{align}

We solve for the reduced costs and get
\begin{align}
    \bar{c}_1 = c_1 - C_B^\top B^{-1} A_1 =
    -1 -
  \begin{bmatrix}
     0 & 0
  \end{bmatrix}
  \begin{bmatrix}
    1 & 0 \\ 0 & 2
  \end{bmatrix}
  \begin{bmatrix}
    1 \\ 1
  \end{bmatrix}
  = -1
\end{align}

\begin{align}
    \bar{c}_2 = c_2 - C_B^\top B^{-1} A_2 =
    -2 -
  \begin{bmatrix}
     0 & 0
  \end{bmatrix}
  \begin{bmatrix}
    1 & 0 \\ 0 & 2
  \end{bmatrix}
  \begin{bmatrix}
    1 \\ -1
  \end{bmatrix}
  = -2
\end{align}

\begin{align}
    d_{Np} = -B^{-1} A_1 = 
    \begin{bmatrix}
        -1 \\ -1
    \end{bmatrix}
\end{align}

\begin{align}
    d_p = 
    \begin{bmatrix}
        1 \\ 0 \\ -1 \\ -1
    \end{bmatrix}
\end{align}

\subsection{Thursday 02/13/2025}

\subsubsection{Geometric Interpretation of Steps}
If we are at a vertex $x$, and we know a descent direction $d$, we want to figure out how far we should go along the direction to get a new $x_0 = x + \alpha d $.
The direction may traverse multiple basic solutions, so we pick the lowest $\alpha_i = \frac{x}{d_i}$ so we ensure we do not violate the constraints.


\subsubsection{Simplex Table}
The simplex algorithm has some paramters calculated or held at each iteration
\begin{itemize}
  \item Reduced cost: $\bar{c} = c^\top - c_B^\top B^{-1} A$
  \item Current iterate: $x_B = B^{-1} b$
  \item Basic direction: $d_B = -B^{-1} A_p$
  \item Objective function value: $-c^\top x$
\end{itemize}

Each of these must be stored.
If we break it apart into a matrix we can store it with a matrix called the simplex table which is $\mathbb{R}^{(m+1)\times (n+1)}$

The simplex table is a convenient way to keep track of all the necessary information during the iterations of the simplex algorithm. It includes the coefficients of the constraints, the objective function, and the current solution.

For our example, the initial simplex table is:

\[
\begin{array}{c|cccc|c}
 & x_1 & x_2 & s_1 & s_2 & \text{RHS} \\
\hline
s_1 & 1 & 1 & 1 & 0 & 1 \\
s_2 & 1 & -1 & 0 & 1 & 1 \\
\hline
\text{Obj} & -1 & -2 & 0 & 0 & 0 \\
\end{array}
\]

Here, $s_1$ and $s_2$ are the slack variables added to convert the inequalities into equalities. The "RHS" column represents the right-hand side of the constraints.

The simplex algorithm has two parts, phase 1 is finding a basic feasible solution using the simplex algorithm and phase 2 is solving given the basic feasible solution.
\subsubsection{Updating the Simplex table}
In order to update a simplex table that has a feasible solution, we can use the example below

For a simplex table with 3 constraints and 6 variables, we can set it up as follows:

\[ 
\begin{array}{c|ccccccc}
 & x_1 & x_2 & x_3 & x_4 & x_5 & x_6 & \text{RHS} \\
\hline
x_1 & 0 & 1.5 & 1 & 1 & -0.5 & 0 & 10 \\
x_4 & 1 & 0.5 & 1 & 0 & 0.5 & 0 &  10 \\
x_6 & 0 & 1 & -1 & 0 & -1 & 1 & 0 \\
\hline
\text{Obj} & 0 & -7 & -2 & 0 & 5 & 0 & 100 \\
\end{array}
\]

Here, we pick $x_2$ as the entering variable since it is the first index with a negative value.
We calculate $\alpha$ for each basic variable to calculate which is the one leaving the simplex table.
\begin{itemize}
  \item $\alpha_1 = \frac{20}{25}$
  \item $\alpha_2 = \frac{20}{25}$
  \item $\alpha_1 = \frac{1}{1}$
\end{itemize}
We pivot the table on row $x_6$, and column $x_2$.
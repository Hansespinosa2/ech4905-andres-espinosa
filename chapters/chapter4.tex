\section{Chapter 4 - LP Solutions}
\subsection{Tuesday 02/11/2025}
\subsubsection{Simplex Algorithm}
For an algorithm that solves an LP, we can define its input as an LP in the form
\begin{align}
  \text{minimize} & \quad c^\top x \\
  \text{subject to} & \quad Ax = b \\
  & \quad x \succeq 0
\end{align}
where $c \in \mathbb{R}^n, b \in \mathbb{R}^m, A \in \mathbb{R}^{m \times n}$.
The optimal solution lies at one of the vertices of the problem which we can represent as $J_1^0, \dots, J_m^0$.
The steps of the algoirthm include
\begin{enumerate}
    \item $B = (A_{j1}, \dots, A_{jm})$
    \item Calculate the reduced cost in all basic directions as 
          $\bar{c}_j = c_j - c_B^\top B^{-1} A_j, \quad \forall j \notin J^k$
    \item If $\bar{c}_j \geq 0 \quad \forall j \notin J^k$ then this is the optimal solution.
          Otherwise, we have a collection of reduced costs for every non-basic variable we have.
          We then pick the calculate them one by one and pick the first one that is less than zero.
          We do this so we don't have to calculate each reduced cost to identify a descent direction.
    \item Calculate the basic variables $x_B = B^{-1} b$.
    \item Calculate the basic components of the basic direction $d_b = B^{-1} A_p$.
    \item Move along $x_B + \alpha d_B$ where $\alpha_i = -\frac{x_{B i}}{d_{b i}}$ if $d_{b i} < 0$
          We will choose the total step $\alpha$ as the $\alpha_i$ that results in the smallest value.
\end{enumerate}
For an example for part 3, consider a reduced cost vector:
\[
\bar{c} = \begin{bmatrix}
2 \\
-2 \\
-4 \\
\vdots \\
-10000
\end{bmatrix}
\]
In this case, we would pick the first value less than zero, which is $-2$.

\subsubsection{Simplex Example}
We can take an example problem
\begin{align}
  \text{minimize} & \quad -x_1 - 2x_2 \\
  \text{subject to} & \quad x_1 + x_2 \leq 1 \\
  & \quad x_1 - x_2 \leq 1 \\
  & \quad x_1, x_2 \geq 0
\end{align}

which can be turned into standard form 
\begin{align}
  \text{minimize} & \quad c^\top x \\
  \text{subject to} & \quad Ax = b \\
  & \quad  x \succeq 0
\end{align}
with parameters 
\begin{align}
    A = 
  \begin{bmatrix}
     1 & 1 & 1 & 0 \\
     1 & -1 & 0 & 1
  \end{bmatrix}
  \quad
  b = 
  \begin{bmatrix}
    1 \\ 1
  \end{bmatrix}
  \quad
  c = 
  \begin{bmatrix}
    1 \\ -2 \\ 0 \\ 0
  \end{bmatrix}
\end{align}

\begin{align}
    J^0 = \{ 3,4 \}
    \quad 
    B = 
    \begin{bmatrix}
        1 & 0 \\ 0 & 2
    \end{bmatrix}
    \quad
    x_B = 
    \begin{bmatrix}
        x_3 \\ x_4
    \end{bmatrix} 
    = B^{-1} b = 
    \begin{bmatrix}
        1 \\ 1
    \end{bmatrix}
\end{align}

We solve for the reduced costs and get
\begin{align}
    \bar{c}_1 = c_1 - C_B^\top B^{-1} A_1 =
    -1 -
  \begin{bmatrix}
     0 & 0
  \end{bmatrix}
  \begin{bmatrix}
    1 & 0 \\ 0 & 2
  \end{bmatrix}
  \begin{bmatrix}
    1 \\ 1
  \end{bmatrix}
  = -1
\end{align}

\begin{align}
    \bar{c}_2 = c_2 - C_B^\top B^{-1} A_2 =
    -2 -
  \begin{bmatrix}
     0 & 0
  \end{bmatrix}
  \begin{bmatrix}
    1 & 0 \\ 0 & 2
  \end{bmatrix}
  \begin{bmatrix}
    1 \\ -1
  \end{bmatrix}
  = -2
\end{align}

\begin{align}
    d_{Np} = -B^{-1} A_1 = 
    \begin{bmatrix}
        -1 \\ -1
    \end{bmatrix}
\end{align}

\begin{align}
    d_p = 
    \begin{bmatrix}
        1 \\ 0 \\ -1 \\ -1
    \end{bmatrix}
\end{align}

\subsection{Thursday 02/13/2025}

\subsubsection{Geometric Interpretation of Steps}
If we are at a vertex $x$, and we know a descent direction $d$, we want to figure out how far we should go along the direction to get a new $x_0 = x + \alpha d $.
The direction may traverse multiple basic solutions, so we pick the lowest $\alpha_i = \frac{x}{d_i}$ so we ensure we do not violate the constraints.


\subsubsection{Simplex Table}
The simplex algorithm has some paramters calculated or held at each iteration
\begin{itemize}
  \item Reduced cost: $\bar{c} = c^\top - c_B^\top B^{-1} A$
  \item Current iterate: $x_B = B^{-1} b$
  \item Basic direction: $d_B = -B^{-1} A_p$
  \item Objective function value: $-c^\top x$
\end{itemize}

Each of these must be stored.
If we break it apart into a matrix we can store it with a matrix called the simplex table which is $\mathbb{R}^{(m+1)\times (n+1)}$

The simplex table is a convenient way to keep track of all the necessary information during the iterations of the simplex algorithm. It includes the coefficients of the constraints, the objective function, and the current solution.

For our example, the initial simplex table is:

\[
\begin{array}{c|cccc|c}
 & x_1 & x_2 & s_1 & s_2 & \text{RHS} \\
\hline
s_1 & 1 & 1 & 1 & 0 & 1 \\
s_2 & 1 & -1 & 0 & 1 & 1 \\
\hline
\text{Obj} & -1 & -2 & 0 & 0 & 0 \\
\end{array}
\]

Here, $s_1$ and $s_2$ are the slack variables added to convert the inequalities into equalities. The "RHS" column represents the right-hand side of the constraints.

The simplex algorithm has two parts, phase 1 is finding a basic feasible solution using the simplex algorithm and phase 2 is solving given the basic feasible solution.
\subsubsection{Updating the Simplex table}
In order to update a simplex table that has a feasible solution, we can use the example below

For a simplex table with 3 constraints and 6 variables, we can set it up as follows:

\[ 
\begin{array}{c|ccccccc}
 & x_1 & x_2 & x_3 & x_4 & x_5 & x_6 & \text{RHS} \\
\hline
x_1 & 0 & 1.5 & 1 & 1 & -0.5 & 0 & 10 \\
x_4 & 1 & 0.5 & 1 & 0 & 0.5 & 0 &  10 \\
x_6 & 0 & 1 & -1 & 0 & -1 & 1 & 0 \\
\hline
\text{Obj} & 0 & -7 & -2 & 0 & 5 & 0 & 100 \\
\end{array}
\]

Here, we pick $x_2$ as the entering variable since it is the first index with a negative value.
We calculate $\alpha$ for each basic variable to calculate which is the one leaving the simplex table.
\begin{itemize}
  \item $\alpha_1 = \frac{20}{25}$
  \item $\alpha_2 = \frac{20}{25}$
  \item $\alpha_1 = \frac{1}{1}$
\end{itemize}
We pivot the table on row $x_6$, and column $x_2$.

\subsection{Tuesday 02/18/2025}
\subsubsection{Simplex Phase 1}
The simplex method is computationally tractable partly due to the fact that the only inverse that needs to be computed is that of $B^{-1}$.
This matrix, the basis matrix with auxiliary variables ends up being equal to the identity matrix, $B = I$.
Therefore, the only identity necessary is $I^{-1} = I$.

We have the following optimization problem
\begin{align}
  \text{minimize} & \quad 2 x_1 + 3 x_2 + 3 x_3 + x_4 - 2 x_5 \\
  \text{subject to} & \quad x_1 + 3x_2 + 4 x_4 + x_5 = 2 \\
  & \quad x_1 + 3x_2 - 3x_4 + x_5 = 2 \\
  & \quad - x_1 - 4 x_2 + 3x_3 = 2 \\
  & \quad \textbf{x} \succeq 0 
\end{align}

which we turn into the auxiliary problem
\begin{align}
  \text{minimize} & \quad x_6 + x_7 + x_8 \\
  \text{subject to} & \quad x_1 + 3x_2 + 4 x_4 + x_5 + x_6 = 2 \\
  & \quad x_1 + 3x_2 - 3x_4 + x_5 + x_7 = 2 \\
  & \quad - x_1 - 4 x_2 + 3x_3 + x_8 = 1 \\
  & \quad \textbf{x} \succeq 0
\end{align}

The initial simplex table with the auxiliary variables in the basis is:

\[ 
\begin{array}{c|cccccccc|c}
 & x_1 & x_2 & x_3 & x_4 & x_5 & x_6 & x_7 & x_8 & \text{RHS} \\
\hline
x_6 & 1 & 3 & 0 & 4 & 1 & 1 & 0 & 0 & 2 \\
x_7 & 1 & 3 & 0 & -3 & 1 & 0 & 1 & 0 & 2 \\
x_8 & -1 & -4 & 3 & 0 & 0 & 0 & 0 & 1 & 1 \\
\hline
\text{Obj} & -1 & -1 & -3 & -1 & -2 & 0 & 0 & 0 & 0 \\
\end{array}
\]

To pivot on $x_3$ and $x_8$, we first need to identify the pivot element, which is the element in the intersection of the row and column of the entering and leaving variables. In this case, the pivot element is $3$.

We then perform row operations to make the pivot element $1$ and all other elements in the pivot column $0$.

The updated simplex table is:

\[ 
\begin{array}{c|cccccccc|c}
 & x_1 & x_2 & x_3 & x_4 & x_5 & x_6 & x_7 & x_8 & \text{RHS} \\ 
\hline
x_6 & 1 + \frac{1}{3} & 3 + \frac{4}{3} & 0 & 4 & 1 & 1 & 0 & -\frac{1}{3} & 2 - \frac{2}{3} \\ 
x_7 & 1 + \frac{1}{3} & 3 + \frac{4}{3} & 0 & -3 & 1 & 0 & 1 & -\frac{1}{3} & 2 - \frac{2}{3} \\ 
x_3 & -\frac{1}{3} & -\frac{4}{3} & 1 & 0 & 0 & 0 & 0 & \frac{1}{3} & \frac{1}{3} \\ 
\hline
\text{Obj} & -1 + \frac{1}{3} & -1 + \frac{4}{3} & 0 & -1 & -2 & 0 & 0 & \frac{1}{3} & \frac{1}{3} \\ 
\end{array}
\]

Here, we have updated the table by performing the necessary row operations to ensure that the pivot element is $1$ and all other elements in the pivot column are $0$.

\subsubsection{Simplex Phase 2}
After finding a basic feasible solution in Phase 1, we proceed to Phase 2 to optimize the original objective function. We start with the feasible solution obtained from Phase 1 and use the simplex method to find the optimal solution.

Consider the following optimization problem:
\begin{align}
  \text{minimize} & \quad 2 x_1 + 3 x_2 + 3 x_3 + x_4 - 2 x_5 \\
  \text{subject to} & \quad x_1 + 3x_2 + 4 x_4 + x_5 = 2 \\
  & \quad x_1 + 3x_2 - 3x_4 + x_5 = 2 \\
  & \quad - x_1 - 4 x_2 + 3x_3 = 2 \\
  & \quad \textbf{x} \succeq 0 
\end{align}

The initial simplex table for Phase 2 is:

\[ 
\begin{array}{c|cccccc|c}
 & x_1 & x_2 & x_3 & x_4 & x_5 & \text{RHS} \\
\hline
x_6 & 1 & 3 & 0 & 4 & 1 & 2 \\
x_7 & 1 & 3 & 0 & -3 & 1 & 2 \\
x_8 & -1 & -4 & 3 & 0 & 0 & 1 \\
\hline
\text{Obj} & -2 & -3 & -3 & -1 & 2 & 0 \\
\end{array}
\]

We identify the entering variable as $x_1$ (most negative coefficient in the objective row) and calculate the ratios to determine the leaving variable:

\[
\begin{array}{c|c}
\text{Variable} & \alpha \\
\hline
x_6 & \frac{2}{1} = 2 \\
x_7 & \frac{2}{1} = 2 \\
x_8 & \frac{1}{-1} = \text{Not feasible} \\
\end{array}
\]

Since both $x_6$ and $x_7$ have the same ratio, we can choose either. Let's choose $x_6$ as the leaving variable. We pivot on the element in row $x_6$ and column $x_1$.

The updated simplex table is:

\[ 
\begin{array}{c|cccccc|c}
 & x_1 & x_2 & x_3 & x_4 & x_5 & \text{RHS} \\
\hline
x_1 & 1 & 3 & 0 & 4 & 1 & 2 \\
x_7 & 0 & -6 & 0 & -7 & 0 & 0 \\
x_8 & 0 & -1 & 3 & 4 & 1 & 3 \\
\hline
\text{Obj} & 0 & 3 & -3 & 7 & 3 & 4 \\
\end{array}
\]

We continue this process until all the coefficients in the objective row are non-negative, indicating that we have found the optimal solution.